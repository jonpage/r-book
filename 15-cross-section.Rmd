# Cross-Section Modeling {#cross-setion}

This lecture uses the following packages:

```
tidyverse
GGally
```

## Introduction

Modeling data gives you the possibility of predicting outside of the sample of data you have
to extrapolate to observational units you have not observed (inference). In this lecture we will focus
on how to do this in a cross-sectional setting (i.e., not over time). 
We will be trying to create a model of salary for recent college graduates. The result will be a model and
a set of parameter estimates that can be used to predict the salary for a recent graduate
our modeling process did not see (i.e., extrapolate).

## Data

The National Science Foundation (NSF) runs the 
[National Survey of College Graduates](https://ncsesdata.nsf.gov/datadownload/).
We'll use this data to compare salaries for different majors.
For the rest of this lecture, I'll assume you've downloaded the 2015 zip 
file and extracted the contents to a folder named "nscg".

### Layout

The raw data is in a fixed width format, so we'll need to know what the layout is.

```{r}
library(tidyverse)
layout <- read_table("data/nscg/LAYOUTPCG15.TXT", skip = 2, col_types = "ciciicc") %>%
  slice(2:n())
```

Let's see if there are any gaps by seing if there is a difference between the start and the last ending plus 1.

```{r}
summary(layout$START - (lag(layout$END) + 1))
```


### Data Dictionary

The data dictionary is stored in an Excel file:

```{r}
library(readxl)
dict <- read_xlsx("data/nscg/Dpcg15.xlsx")
```

The data dictionary provides more detail than the layout file, which is useful for identifying
the variables we want to work with.

### The 2015 National Survey of College Graduates

Processing this whole file will take some time.

```{r}
raw_survey <- read_fwf("data/nscg/EPCG15.DAT", fwf_widths(layout$LENGTH, col_names = layout$LABEL))
```

For the factor variables, we can look at the `Ppcg15.sas` file for the mappings from
integer values into character vectors. The below functions accept a vector of integers and return a
character vector.

### Variable Definitions

From looking at the Excel file, we can determine the label mapping for each variable.
The label mapping name is in the `SAS_FMT` column. We can then look at the `Ppcg15.sas`
file to see the corresponding mapping. We just need to edit these mappings slightly so
they fit into a factor definition. (There do exist packages that will do this for you,
but the following process gives you more control.)

```{r}
ethnicity <- function(x) {
  factor(
    x, 
    levels = 1:7, 
    labels = c(
      "Asian, non-Hispanic ONLY",
      "American Indian/Alaska Native, non-Hispanic ONLY",
      "Black, non-Hispanic ONLY",
      "Hispanic, any race",
      "White, non-Hispanic ONLY",
      "Non-Hispanic Native Hawaiian/Other Pacific Islander ONLY",
      "Multiple Race"
    )
  )
}

work_activities <- function(x) {
  work_mapping <- matrix(
    ncol = 2, byrow = TRUE,
    data = c(
      "01", "Accounting, finance, contracts",
      "02", "Basic res.-study to gain sci. knwldg prima. for its own sake",
      "03", "Apld. res.-study to gain sci. knwldg to meet recognized need",
      "04", "Dev.-knowledge from res. for the prod. of materials, devices",
      "05", "Design of equipment, processes, structures, models",
      "06", "Computer applications, programming, systems development",
      "07", "Human Resources - inc. recruiting, personnel dev, training",
      "08", "Managing or supervising people or projects",
      "09", "Production, operations, maintenance (e.g., chip production)",
      "10", "Prof. services (healthcare, fin. serv., legal serv., etc.)",
      "11", "Sales, purchasing, marketing",
      "12", "Quality or productivity management",
      "13", "Teaching",
      "14", "Other work activity"
    )
  )
  return(factor(x, levels = work_mapping[,1], labels = work_mapping[,2]))
}

fields <- function(x) {
  field_mapping <- matrix(
    ncol = 2, byrow = TRUE,
    data = c(
      11, "Computer and information sciences",
      12, "Mathematics and statistics",
      21, "Agricultural and food sciences",
      22, "Biological sciences",
      23, "Environmental life sciences",
      31, "Chemistry, except biochemistry",
      32, "Earth, atmospheric and ocean sciences",
      33, "Physics and astronomy",
      34, "Other physical sciences",
      41, "Economics",
      42, "Political and related sciences",
      43, "Psychology",
      44, "Sociology and anthropology",
      45, "Other social sciences",
      51, "Aerospace, aeronautical and astronautical engineering",
      52, "Chemical engineering",
      53, "Civil and architectural engineering",
      54, "Electrical and computer engineering",
      55, "Industrial engineering",
      56, "Mechanical engineering",
      57, "Other engineering",
      61, "Health",
      62, "Science and mathematics teacher education",
      63, "Technology and Technical Fields",
      64, "Other S&E related fields",
      71, "Management and administration fields",
      72, "Education, except science and math teacher education",
      73, "Social service and related fields",
      74, "Sales and marketing fields",
      75, "Art and Humanities Fields",
      76, "Other Non-S&E fields"
    )
  )
  return(factor(x, levels = as.numeric(field_mapping[,1]), labels = field_mapping[,2]))
}

locations <- function(x) {
  location_mapping <- matrix(
    ncol = 2, byrow = TRUE,
    data = c(
      "099", "US, Unspecified",
      "100", "Albania",
      "102", "Austria",
      "103", "Belgium",
      "104", "Bulgaria",
      "109", "France",
      "110", "Germany, not specified",
      "116", "Greece",
      "119", "Ireland",
      "120", "Italy",
      "126", "Netherlands",
      "128", "Poland",
      "132", "Romania",
      "134", "Spain",
      "136", "Sweden",
      "137", "Switzerland",
      "138", "United Kingdom, not specified",
      "139", "England",
      "140", "Scotland",
      "142", "Northern Ireland",
      "148", "Europe, not specified",
      "149", "Central Europe, not specified",
      "150", "Eastern Europe, not specified",
      "152", "Northern Europe, not specified",
      "153", "Southern Europe, not specified",
      "154", "Western Europe, not specified",
      "156", "Serbia/Montenegro/Kosovo",
      "160", "Croatia",
      "180", "USSR",
      "186", "Belarus (Byelarus)",
      "187", "Russia",
      "193", "Ukraine",
      "202", "Bangladesh",
      "207", "China",
      "210", "India",
      "212", "Iran",
      "213", "Iraq",
      "214", "Israel",
      "215", "Japan",
      "216", "Jordan",
      "217", "Korea, not specified",
      "218", "South Korea",
      "222", "Lebanon",
      "223", "Macao",
      "227", "Nepal",
      "229", "Pakistan",
      "231", "Philippines",
      "232", "Qatar",
      "233", "Saudi Arabia",
      "236", "Sri Lanka",
      "238", "Taiwan",
      "239", "Thailand",
      "240", "Turkey",
      "242", "Vietnam",
      "245", "Asia, not specified",
      "247", "East Asia, not specified",
      "252", "Middle East, not specified",
      "255", "Southeast Asia, not specified",
      "257", "Southwest Asia, not specified",
      "301", "Canada",
      "304", "North America, not specified",
      "312", "El Salvador",
      "315", "Mexico",
      "318", "Central America, not specified",
      "337", "Cuba",
      "339", "Dominican Republic",
      "343", "Jamaica",
      "353", "Caribbean, not specified",
      "375", "Argentina",
      "377", "Brazil",
      "379", "Colombia",
      "380", "Ecuador",
      "385", "Peru",
      "388", "Venezuela",
      "389", "South America, not specified",
      "408", "Cameroon",
      "415", "Egypt",
      "417", "Ethiopia",
      "421", "Ghana",
      "436", "Morocco",
      "437", "Mozambique",
      "440", "Nigeria",
      "449", "South Africa",
      "462", "Africa, not specified",
      "463", "Central Africa, not specified",
      "464", "Eastern Africa, not specified",
      "468", "North Africa, not specified",
      "469", "Western Africa, not specified",
      "470", "Southern Africa, not specified",
      "471", "Eritrea",
      "501", "Australia",
      "514", "New Zealand",
      "527", "Oceania, not specified"
    )
  )
  return(factor(x, levels = location_mapping[,1], labels = location_mapping[,2]))
}
```


```{r}
survey <- raw_survey %>%
  transmute(
    age = U_DEM_AGE,
    gender = factor(U_DEM_GENDER),
    race_ethnicity = ethnicity(U_DEM_MULTIPLE_RACE_ETHNICITY_CAT),
    years_since_degree = 2015 - M_ED_MR_DEGREE_AWARD_YR,
    degree_type = factor(
      M_ED_MR_DEGREE_TYPE, 
      levels = 1:4, 
      labels = c('Bachelors', 'Masters', 'Doctorate', 'Professional')
    ),
    current_location = locations(U_RESPONDENT_LOCATION_STATE_COUNTRY),
    highschool_location = locations(L_ED_HS_SCHOOL_ST_CTRY_CD),
    school_in_US = M_ED_MR_SCHOOL_REGION_US_NONUS == 'Y',
    moved = current_location != highschool_location,
    r1 = M_ED_MR_SCHOOL_CARNEGIE_CLS == "11",
    field_of_study_group = factor(case_when(
      O_ED_HD_MAJOR_ED_GRP_MAJOR_NEW == 1 ~ 'Computer and mathematical sciences',
      O_ED_HD_MAJOR_ED_GRP_MAJOR_NEW == 2 ~ 'Biological, agricultural and environmental life sciences',
      O_ED_HD_MAJOR_ED_GRP_MAJOR_NEW == 3 ~ 'Physical and related sciences',
      O_ED_HD_MAJOR_ED_GRP_MAJOR_NEW == 4 ~ 'Social and related sciences',
      O_ED_HD_MAJOR_ED_GRP_MAJOR_NEW == 5 ~ 'Engineering',
      O_ED_HD_MAJOR_ED_GRP_MAJOR_NEW == 6 ~ 'S&E-Related Fields',
      O_ED_HD_MAJOR_ED_GRP_MAJOR_NEW == 7 ~ 'Non-S&E'
    )),
    field_of_study = fields(O_ED_HD_MAJOR_ED_GRP_MINOR_NEW),
    in_school = case_when(
      N_ED_REF_WK_ENROLL_FT_PT_IND == '1' ~ TRUE,
      N_ED_REF_WK_ENROLL_FT_PT_IND == '2' ~ TRUE,
      TRUE ~ FALSE
    ),
    work_activity = work_activities(F_JOB_WRK_ACTIVITY_PRIMRY),
    salary = ifelse(H_JOB_SALARY_ANN == 9999998, NA, H_JOB_SALARY_ANN),
    income = ifelse(H_JOB_TOTAL_INCOME == 9999998, NA, H_JOB_TOTAL_INCOME)
  )
```


### Training/Validation/Test Sets

There are several things we need to do with this data.

1. We want to create candidate models of salary
2. We want to select a model based on its predictive accuracy
3. We want to produce an estimate of the predictive accuracy of our chosen model

To accomplish these three goals, we need divide our data into three parts. The reason we
need to split our data, is to avoid bias in our inferences. Bias is a systematic mistake in our
inferences, which is bad. Since we are decreasing our sample
size we will be increasing the variance of our inferences. This [bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)
is an important concept in machine learning, but here we'll just recognize it exists.

We will call the data for (1) our training dataset, the data for (2) our validation dataset, and the
data for (3) our test set. For simplicity here we'll split our data 80%-10%-10% into our training-validation-test sets. An easy way to grab random chunks of the data is to permute the indices, then take the first 80%, then 10%,
etc.

Let's make a decision up front to predicr
```{r}
survey <- survey %>% filter(salary > 0)
```


```{r}
train_size <- round(nrow(survey) * 0.8)
validation_size <- round(nrow(survey) * 0.1)
test_size <- nrow(survey) - train_size - validation_size
permuted_indices <- sample(1:nrow(survey))

train <- survey[permuted_indices[1:train_size],]
validation <- survey[permuted_indices[(train_size + 1):validation_size],]
test <- survey[permuted_indices[(validation_size + 1):length(permuted_indices)],]
```

## Exploratory Data Analysis

Let's begin by exploring our training set. We can start with a quick summary of all
variables to see which could be meaningful in our model:

```{r}
summary(train)
```

We can see that our location variables are mostly NAs. We will drop these variables from our analysis to
avoid several issues like multicollinearity and sampling bias.

```{r}
library(GGally)
train %>%
  sample_n(1000) %>%
  as.data.frame() %>%
  GGally::ggscatmat(alpha = 0.1)
```

## Simple linear model

```{r}
basic_model <- lm(log(salary + 1) ~ I(age - 25) + I((age - 25)^2) , data = train)
summary(basic_model)
```

Based on the above results which job types are associated with higher salaries?

## Model selection

We can use the validation set to see how well our model performs in predicting
salary for people not in our training set. By comparing the prediction on the performance
on several model alternatives, we can select the best prediction model.

### Model alternatives

In a real world situation you can test every possible linear combination of your
variables on the right-hand side. Entirely different models (e.g., random forest regression)
may be even better candidates, but for simplicity we'll focus on a small set 
of linear models of salary.
```{r}
school_model <- lm(
  log(salary + 1) ~ 
    I(age - 25) + I((age - 25)^2) + 
    years_since_degree + degree_type + r1 + field_of_study_group, 
  data = train
)
demo_model <- lm(
  log(salary + 1) ~ 
    I(age - 25) + I((age - 25)^2) + 
    gender + race_ethnicity, 
  data = train
)
current_model <- lm(
  log(salary + 1) ~ 
    I(age - 25) + I((age - 25)^2) + 
    in_school + work_activity, 
  data = train
)
kitchen_sink_model <- lm(
  log(salary + 1) ~ 
    I(age - 25) + I((age - 25)^2) + 
    years_since_degree + degree_type + r1 + field_of_study_group +
    gender + race_ethnicity +
    in_school + work_activity, 
  data = train
)
summary(kitchen_sink_model)
```

### Comparing model performance

Now we can compare the performance of each of these models against
the validation dataset. Let's walk step-by-step through the process
of calculating the root mean squared prediction error (or RMSPE, or RMSE)
with just the school prediction.
```{r}
school_prediction <- predict(school_model, validation)
salary_prediction <- exp(school_prediction) - 1
prediction_error <- salary_prediction - validation$salary
school_rmse <- sqrt(mean(prediction_error^2, na.rm = TRUE))
school_rmse
```

Now let's compare that to the RMSE for the other models.
```{r}
demo_rmse <- sqrt(mean((exp(predict(demo_model, validation)) - 1 - validation$salary)^2, na.rm = TRUE))
demo_rmse
current_rmse <- sqrt(mean((exp(predict(current_model, validation)) - 1 - validation$salary)^2, na.rm = TRUE))
current_rmse
kitchen_rmse <- sqrt(mean((exp(predict(kitchen_sink_model, validation)) - 1 - validation$salary)^2, na.rm = TRUE))
kitchen_rmse
```

The `kitchen_model` outperforms the others (lowest RMSE) so we will use it in our final step.
Keep in mind there are many alternative methods of modeling salary, so the above test
should not be considered exhaustive.

## Predictions from the selected model

Finally, we can use our `test` dataset to evaluate the expected error for predictions from
our chosen model. The only thing that changes relative to the `kitchen_rmse` we calculated
above is swapping `validation` with `test`.

```{r}
test_rmse <- sqrt(mean((exp(predict(kitchen_sink_model, test)) - 1 - test$salary)^2, na.rm = TRUE))
test_rmse
```

```{r}
other_test_rmse <- sqrt(mean((predict(kitchen_sink_model, test) - log(test$salary + 1))^2, na.rm = TRUE))
other_test_rmse
```

What this number gives us is a typical error from our model predictions. The fact that this
error is so large tells us that our model does a really poor job of predicting salary.

## Assignment

Add variables on parental background, estimate an updated kitchen sink model including
these new variables, and report the RMSE on the validation and test sets.

```
N_ED_UG_FINAN_SUPP_GIFTS
W_DEM_PARENT_FATHERS_ED_LEVEL
W_DEM_PARENT_MOTHERS_ED_LEVEL
```

## See also

There are many approaches to model selection and a broad array of
tools within R to help you along the way. Here's a sampling:

* http://r4ds.had.co.nz/model-building.html
* https://www.statmethods.net/stats/regression.html
* http://r-statistics.co/Model-Selection-in-R.html
